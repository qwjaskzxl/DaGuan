{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import shelve\n",
    "from sklearn import metrics\n",
    "import time\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, mutual_info_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time consumption on loading: 1.3846826553344727\n"
     ]
    }
   ],
   "source": [
    "load_start = time.time()\n",
    "shelve_file = shelve.open('../data/sample')\n",
    "X_train = shelve_file['X_train']\n",
    "y_train = shelve_file['y_train']\n",
    "X_test = shelve_file['X_test']\n",
    "print('Time consumption on loading:',time.time()-load_start)\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,4), min_df=3, max_df=0.9, use_idf=1, smooth_idf=1, sublinear_tf=1)\n",
    "tfidf.fit(X_train)\n",
    "X_train = tfidf.transform(X_train)\n",
    "X_test = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amax/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 classifiers...\n",
      "Fitting classifier1: sgdclassifier (1/3)\n",
      "Fitting classifier2: logisticregression (2/3)\n",
      "Fitting classifier3: multinomialnb (3/3)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.98      0.98      0.98      5341\n",
      "         10       0.99      0.99      0.99      4927\n",
      "         11       0.99      0.99      0.99      3514\n",
      "         12       0.99      0.99      0.99      5242\n",
      "         13       0.99      0.99      0.99      7818\n",
      "         14       0.99      0.99      0.99      6693\n",
      "         15       1.00      1.00      1.00      7082\n",
      "         16       0.99      0.98      0.99      2981\n",
      "         17       0.98      0.99      0.99      3058\n",
      "         18       1.00      1.00      1.00      6970\n",
      "         19       0.98      0.99      0.98      5483\n",
      "          2       0.99      0.99      0.99      2889\n",
      "          3       1.00      1.00      1.00      8217\n",
      "          4       0.99      0.99      0.99      3751\n",
      "          5       0.99      0.98      0.99      2335\n",
      "          6       1.00      1.00      1.00      6804\n",
      "          7       0.99      0.99      0.99      3010\n",
      "          8       0.99      0.99      0.99      6925\n",
      "          9       1.00      1.00      1.00      7522\n",
      "\n",
      "avg / total       0.99      0.99      0.99    100562\n",
      "\n",
      "[[5233   13    6    2   24    2    1   15    5    2    7    2    1    3\n",
      "     5    0    4   14    2]\n",
      " [   8 4872    1    1    2    3    0    0    4    0    4    0    2    0\n",
      "     0    2    0   27    1]\n",
      " [   2    0 3481    5    2    0    2    0    1    2    7    1    5    0\n",
      "     0    1    2    2    1]\n",
      " [   4    2    3 5191    5    1    1    1    3    3   14    0    3    2\n",
      "     1    0    3    1    4]\n",
      " [  14    3    4    4 7744    8    2    4    2    0   12    2    4    0\n",
      "     1    1    1    9    3]\n",
      " [   4    2    1    1   11 6623    4    1   22    2    4    1    3    6\n",
      "     0    3    2    3    0]\n",
      " [   1    0    7    0    0    0 7065    0    0    1    1    0    5    1\n",
      "     0    0    0    0    1]\n",
      " [  17    0    0    1    4    3    1 2936    1    1    1    1    0    1\n",
      "     2    1    0   11    0]\n",
      " [   6    3    0    1    1    8    2    0 3026    1    2    2    1    2\n",
      "     0    0    3    0    0]\n",
      " [   0    0    2    2    2    0    0    0    0 6950   10    0    0    0\n",
      "     0    1    0    0    3]\n",
      " [   7    2    8    8   13    4    3    0    4    8 5405    3    2    2\n",
      "     1    0    3    5    5]\n",
      " [   5    1    2    0    1    0    0    0    0    2    3 2873    0    0\n",
      "     1    0    1    0    0]\n",
      " [   0    2    5    1    0    1    1    0    0    2    2    1 8193    0\n",
      "     0    8    1    0    0]\n",
      " [   5    1    0    3    1    5    1    0    1    1    1    0    0 3728\n",
      "     1    1    1    1    0]\n",
      " [  15    1    1    2    2    2    0    0    0    0    2    1    3    2\n",
      "  2294    0    2    8    0]\n",
      " [   1    2    0    0    0    0    1    0    0    0    1    0    8    1\n",
      "     0 6789    0    1    0]\n",
      " [   3    1    6    4    4    4    6    0    2    0    8    1    0    2\n",
      "     0    0 2966    1    2]\n",
      " [  15   16    3    6   11    7    1   11    3    2    5    0    1    0\n",
      "     5    3    1 6833    2]\n",
      " [   2    0    4    0    4    0    2    0    1    2    4    0    1    0\n",
      "     0    0    0    0 7502]]\n",
      "time comsumption is 2160.1137466430664\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "sgd =  SGDClassifier(loss=\"modified_huber\", alpha=0.00002, n_jobs=-1,penalty = 'l2')\n",
    "lsvc = LinearSVC(C=0.8, loss='squared_hinge', intercept_scaling=1, tol=0.0002, multi_class='ovr')\n",
    "rfc =  RandomForestClassifier()\n",
    "knn =  KNeighborsClassifier()\n",
    "svc =  SVC(kernel='linear', C=0.8,probability=True)\n",
    "mnb =  MultinomialNB(alpha = 0.001)\n",
    "lr = LogisticRegression(penalty = 'l2',C=10)\n",
    "dtc = DecisionTreeClassifier()\n",
    "gdbt = GradientBoostingClassifier()\n",
    "clf1 = sgd\n",
    "clf2 = lr\n",
    "clf3 = rfc\n",
    "\n",
    "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3], meta_classifier=lr, use_probas=True,verbose=1)\n",
    "sclf.fit(X_train,y_train)\n",
    "prediction = sclf.predict(X_train)\n",
    "print(metrics.classification_report(y_train,prediction))#分类报告\n",
    "print(metrics.confusion_matrix(y_train,prediction))#混淆矩阵\n",
    "#scores = cross_val_score(sclf, X_train, y_train , cv=3, scoring='f1_macro')\n",
    "#print(scores)\n",
    "'''\n",
    "for clf, label in zip([clf1, clf2, clf3, sclf], \n",
    "                      ['SGD', \n",
    "                       'LR', \n",
    "                       'RFC',\n",
    "                       'StackingClassifier']):\n",
    " \n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=3, scoring='f1_macro')\n",
    "    print(\"f1_score: %0.2f (+/- %0.2f) [%s]\" \n",
    "          % (scores.mean(), scores.std(), label))\n",
    "'''\n",
    "print('time comsumption is',time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 classifiers...\n",
      "Fitting classifier1: sgdclassifier (1/3)\n",
      "Fitting classifier2: logisticregression (2/3)\n",
      "Fitting classifier3: multinomialnb (3/3)\n",
      "Fitting 3 classifiers...\n",
      "Fitting classifier1: sgdclassifier (1/3)\n",
      "Fitting classifier2: logisticregression (2/3)\n",
      "Fitting classifier3: multinomialnb (3/3)\n",
      "Fitting 3 classifiers...\n",
      "Fitting classifier1: sgdclassifier (1/3)\n",
      "Fitting classifier2: logisticregression (2/3)\n",
      "Fitting classifier3: multinomialnb (3/3)\n",
      "[ 0.76148277  0.7617295   0.76030189]\n",
      "0.761171385819 +/- 0.0012460435034\n",
      "Time consumption on cv 3966.495723247528\n"
     ]
    }
   ],
   "source": [
    "#交叉验证\n",
    "vali_start = time.time()\n",
    "scores = cross_val_score(sclf, X_train, y_train , cv=3, scoring='f1_macro')#交叉验证\n",
    "print(scores) #各组分数\n",
    "print(scores.mean(),'+/-',scores.std()*2) #平均分\n",
    "print(\"Time consumption on cv\",time.time( ) - vali_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time consumption on save 107.34028768539429\n"
     ]
    }
   ],
   "source": [
    "\n",
    "save_start = time.time()\n",
    "joblib.dump(sclf, 'model/master.m', compress=3)#保存模型\n",
    "print(\"Time consumption on save\",time.time( ) - save_start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time comsumption on test 22.84069037437439\n",
      "Total Time comsumption: 6257.039233207703\n"
     ]
    }
   ],
   "source": [
    "test_start = time.time()\n",
    "#预测\n",
    "prediction = sclf.predict(X_test)\n",
    "print('Time comsumption on test',time.time()-test_start)\n",
    "#保存结果\n",
    "f_out = open('stacking.csv', 'w')\n",
    "f_out.write(\"id,class\"+\"\\n\")\n",
    "for i in range(X_test.shape[0]):\n",
    "    f_out.write(str(i)+\",\"+str(prediction[i])+'\\n')\n",
    "f_out.close()\n",
    "print('Total Time comsumption:',time.time()-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
