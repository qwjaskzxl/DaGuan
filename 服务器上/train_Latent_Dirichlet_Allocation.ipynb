{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time consumption on loading: 3.482760190963745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amax/anaconda3/lib/python3.6/site-packages/gensim/models/ldamodel.py:1023: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n",
      "/home/amax/anaconda3/lib/python3.6/site-packages/gensim/models/ldamodel.py:676: RuntimeWarning: overflow encountered in true_divide\n",
      "  gammad = self.alpha + expElogthetad * np.dot(cts / phinorm, expElogbetad.T)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12276, 1999)\n",
      "Time consumption on training1: 1295.7346184253693\n",
      "Accuracy: 0.50 (+/- 0.02)\n",
      "Time consumption on training1+2: 1298.724730014801\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         1\n",
      "       0.64      0.17      0.27       537\n",
      "        10\n",
      "       0.46      0.57      0.51       478\n",
      "        11\n",
      "       0.48      0.27      0.35       337\n",
      "        12\n",
      "       0.63      0.24      0.35       531\n",
      "        13\n",
      "       0.46      0.61      0.53       777\n",
      "        14\n",
      "       0.57      0.71      0.63       647\n",
      "        15\n",
      "       0.45      0.61      0.52       752\n",
      "        16\n",
      "       0.47      0.05      0.08       306\n",
      "        17\n",
      "       0.65      0.47      0.55       287\n",
      "        18\n",
      "       0.66      0.79      0.72       680\n",
      "        19\n",
      "       0.43      0.10      0.16       577\n",
      "         2\n",
      "       0.56      0.73      0.63       279\n",
      "         3\n",
      "       0.47      0.59      0.52       808\n",
      "         4\n",
      "       0.68      0.06      0.11       369\n",
      "         5\n",
      "       0.51      0.18      0.27       223\n",
      "         6\n",
      "       0.58      0.61      0.59       675\n",
      "         7\n",
      "       0.60      0.42      0.49       313\n",
      "         8\n",
      "       0.44      0.74      0.55       670\n",
      "         9\n",
      "       0.54      0.91      0.68       753\n",
      "\n",
      "avg / total       0.53      0.52      0.48      9999\n",
      "\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "TfidfVectorizer - Vocabulary wasn't fitted.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-04b76181a319>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;31m# X_test = X_test.toarray()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amax/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents, copy)\u001b[0m\n\u001b[1;32m   1407\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_tfidf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'The tfidf vector is not fitted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amax/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m    918\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amax/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_check_vocabulary\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;34m\"\"\"Check if vocabulary is empty or missing (not fit-ed)\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%(name)s - Vocabulary wasn't fitted.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vocabulary_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amax/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: TfidfVectorizer - Vocabulary wasn't fitted."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "import time\n",
    "import random\n",
    "\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer #计算tfidf\n",
    "from sklearn.feature_extraction.text import CountVectorizer  #计算df\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  #“一步到位”\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.externals import joblib # to save\n",
    "from sklearn import metrics\n",
    "\n",
    "id_num = []\n",
    "word_article = []\n",
    "words_article = []\n",
    "label = []\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "load_start = time.time()\n",
    "importlib.reload(sys)\n",
    "with open('train_set.csv','r',encoding = 'utf-8') as f:\n",
    "    lines = f.readlines()[1:]\n",
    "#     random.shuffle(lines) #注意用法\n",
    "    for line in lines[1:10000]:\n",
    "        line = line.split(',')\n",
    "        X_train.append(line[2])\n",
    "        y_train.append(line[3])\n",
    "    for line in lines[100000:]: #划分出测试集\n",
    "        line = line.split(',')\n",
    "        X_test.append(line[2])\n",
    "        y_test.append(line[3])\n",
    "words = [[] for i in range(len(X_train) + len(X_test))]   \n",
    "i = 0\n",
    "for i in range(len(X_train)):\n",
    "    for j in X_train[i].split(' '):\n",
    "        words[i].append(j)\n",
    "#     corpus[i].append(j for j in X_train[i].split(' ')) #错的？\n",
    "i += 1\n",
    "ii =0\n",
    "for i in range(i,i+len(X_test)):\n",
    "    for j in X_test[ii].split(' '):\n",
    "        words[i].append(j)\n",
    "    ii += 1\n",
    "# print(corpus[-1])\n",
    "print(\"Time consumption on loading:\",time.time() - load_start)\n",
    "\n",
    "train_start = time.time()\n",
    "dictionary = corpora.Dictionary(words)\n",
    "# print(dictionary)\n",
    "corp = [ dictionary.doc2bow(word) for word in words ] #词频统计+one hot\n",
    "tfidf_model = models.TfidfModel(corpus=words, dictionary=dictionary)#这里用words和corp训练结果是一样的\n",
    "corp_tfidf = [tfidf_model[doc] for doc in corp]\n",
    "# print(len(corp_tfidf), corp_tfidf[0])\n",
    "lda = LdaModel(corpus=corp_tfidf, id2word=dictionary, num_topics=2000) #可以直接换成LsiModel\n",
    "corp_lda = [lda[doc] for doc in corp]\n",
    "data = []\n",
    "rows = []\n",
    "cols = []\n",
    "line_count = 0\n",
    "for line in corp_lda:  # corp_lda 是之前由gensim生成的lsi向量\n",
    "    for elem in line:\n",
    "        rows.append(line_count)\n",
    "        cols.append(elem[0])\n",
    "        data.append(elem[1])\n",
    "    line_count += 1\n",
    "lda_sparse_matrix = csr_matrix((data,(rows,cols))) \n",
    "lda_matrix = lda_sparse_matrix.toarray()  \n",
    "print(lda_matrix.shape)\n",
    "X_train = lda_matrix[0:9999]\n",
    "\n",
    "\n",
    "\n",
    "# vect = TfidfVectorizer(ngram_range=(1,2), min_df=3, max_df=0.95, use_idf=1, smooth_idf=1, sublinear_tf=1)\n",
    "# vect.fit(X_train) # 或者直接X_train = vect.fit_transform(X_train)\n",
    "# X_train = vect.transform(X_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# X_train = X_train.toarray() #由稀疏矩阵变成ndarray类型的完整矩阵。。？\n",
    "# pca = PCA(n_components = 10000)\n",
    "# print(X_train.shape)\n",
    "# X_train = pca.fit_transform(X_train)\n",
    "# print(X_train.shape)\n",
    "print(\"Time consumption on training1:\",time.time() - train_start)\n",
    "\n",
    "\n",
    "clf = svm.LinearSVC(C=0.5)\n",
    "# clf = svm.SVC(kernel='linear', C=1, )\n",
    "# clf = SGDClassifier(loss=\"modified_huber\", )#penalty=”elasticnet”: L2和L1的convex组合; (1 - l1_ratio) * L2 + l1_ratio * L1\n",
    "clf.fit(X_train, y_train)\n",
    "scores = cross_val_score(clf, X_train, y_train , cv=5)\n",
    "# print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "# joblib.dump(clf, 'lineSVM_20000__.m')\n",
    "print(\"Time consumption on training1+2:\",time.time() - train_start)\n",
    "\n",
    "\n",
    "test_start = time.time()\n",
    "# clf = joblib.load('lineSVM_20000__.m')\n",
    "prediction = clf.predict(X_train)\n",
    "print(metrics.classification_report(y_train,prediction))\n",
    "X_test = vect.transform(X_test)\n",
    "# X_test = X_test.toarray()\n",
    "print(X_test.shape)\n",
    "prediction = clf.predict(X_test) \n",
    "print(metrics.classification_report(y_test,prediction))\n",
    "# print(metrics.confusion_matrix(y_test,prediction))\n",
    "print(\"Time consumption on testing:\",time.time() - test_start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
