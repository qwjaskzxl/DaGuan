{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time consumption on loading: 1.6925623416900635\n",
      "(4999, 190073)\n",
      "Time consumption on training1: 23.50469422340393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amax/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4999, 18)\n",
      "[ 0.99801193  0.99302094  0.99100899  0.99099099  0.99292929]\n",
      "Accuracy: 0.99 (+/- 0.01)\n",
      "Time consumption on training1+2: 215.6636574268341\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 18 features per sample; expecting 190073",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-cdbfc080ef31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0mtest_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;31m# clf = joblib.load('lineSVM_20000__.m')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amax/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \"\"\"\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amax/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0;32m--> 305\u001b[0;31m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[0;31mValueError\u001b[0m: X has 18 features per sample; expecting 190073"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "import time\n",
    "import random\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer #计算tfidf\n",
    "from sklearn.feature_extraction.text import CountVectorizer  #计算df\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  #“一步到位”\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.externals import joblib # to save\n",
    "from sklearn import metrics\n",
    "\n",
    "id_num = []\n",
    "word_article = []\n",
    "words_article = []\n",
    "label = []\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "load_start = time.time()\n",
    "importlib.reload(sys)\n",
    "with open('train_set.csv','r',encoding = 'utf-8') as f:\n",
    "    lines = f.readlines()[1:]\n",
    "    # random.shuffle(lines) #注意用法\n",
    "    for line in lines[1:5000]:\n",
    "        line = line.split(',')\n",
    "        X_train.append(line[2])\n",
    "        y_train.append(line[3])\n",
    "    for line in lines[100000:]: #划分出测试集\n",
    "        line = line.split(',')\n",
    "        X_test.append(line[2])\n",
    "        y_test.append(line[3])\n",
    "print(\"Time consumption on loading:\",time.time() - load_start)\n",
    "\n",
    "train_start = time.time()\n",
    "vect = TfidfVectorizer(ngram_range=(1,2), min_df=3, max_df=0.9, use_idf=1, smooth_idf=1, sublinear_tf=1)\n",
    "vect.fit(X_train) # 或者直接X_train = vect.fit_transform(X_train)\n",
    "X_train = vect.transform(X_train)\n",
    "X_train = X_train.toarray() #由稀疏矩阵变成ndarray类型的完整矩阵。。？\n",
    "pca = PCA(n_components = 18)\n",
    "# X_train = pca.fit_transform(X_train)\n",
    "print(X_train.shape)\n",
    "print(\"Time consumption on training1:\",time.time() - train_start)\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components=None)\n",
    "lda.fit(X_train, y_train)\n",
    "X_train = lda.transform(X_train)\n",
    "print(X_train.shape)\n",
    "\n",
    "# clf = svm.LinearSVC(C=0.5)\n",
    "# clf = svm.SVC(kernel='linear', C=1, )\n",
    "# clf = SGDClassifier(loss=\"modified_huber\", )#penalty=”elasticnet”: L2和L1的convex组合; (1 - l1_ratio) * L2 + l1_ratio * L1\n",
    "# clf.fit(X_train, y_train)\n",
    "scores = cross_val_score(lda, X_train, y_train , cv=5)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "# joblib.dump(clf, 'lineSVM_20000__.m')\n",
    "print(\"Time consumption on training1+2:\",time.time() - train_start)\n",
    "\n",
    "test_start = time.time()\n",
    "# clf = joblib.load('lineSVM_20000__.m')\n",
    "prediction = lda.predict(X_train)\n",
    "print(metrics.classification_report(y_train,prediction))\n",
    "X_test = vect.transform(X_test)\n",
    "X_test = X_test.toarray()\n",
    "X_test = pca.fit_transform(X_test)\n",
    "print(X_test.shape)\n",
    "prediction = lda.predict(X_test)\n",
    "print(metrics.classification_report(y_test,prediction))\n",
    "# print(metrics.confusion_matrix(y_test,prediction))\n",
    "print(\"Time consumption on testing:\",time.time() - test_start)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
